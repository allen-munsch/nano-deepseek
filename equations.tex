\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{physics}
\usepackage{bm}
\usepackage{natbib}

\title{Mathematical Formulation of DeepSeek with Hybrid Quantum-Classical Implementation}
\author{DeepSeek Implementation}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
This document presents the mathematical formulation of a hybrid quantum-classical language model implementation. The approach combines classical deep learning with actual quantum computing operations through Qiskit, respecting real hardware constraints and limitations. Quantum operations are used where beneficial while acknowledging current NISQ device limitations.
\end{abstract}

\section*{Introduction}
This document describes the mathematical formulation of a quantum-enhanced language model implementation. The codebase combines classical transformer architecture with quantum computing concepts, including quantum layers for processing, quantum-inspired optimization, and Monte Carlo methods for uncertainty estimation. Key components include quantum state evolution through rotation gates, error correction mechanisms, and quantum-enhanced attention mechanisms. The implementation focuses on maintaining quantum coherence while providing practical benefits for language modeling tasks.

\section{Model Architecture}

\subsection{Quantum State Preparation and Evolution}
The quantum layer implements proper quantum state preparation and evolution:

\subsubsection{Amplitude Encoding}
Classical to quantum state conversion with proper amplitude encoding:
\begin{equation}
|\psi_{\text{in}}\rangle = \sum_{i=0}^{2^{\lceil\log_2(n)\rceil}-1} r_i e^{i\theta_i}|i\rangle
\end{equation}

where amplitudes $\alpha_i$ are computed as:
\begin{equation}
\alpha_i = \text{sign}(x_i)\frac{|x_i|}{\|\mathbf{x}\|_2}e^{i\phi_i}, \quad \phi_i = \arccos(|x_i|/\|\mathbf{x}\|_2)
\end{equation}

ensuring proper normalization:
\begin{equation}
\sum_i |\alpha_i|^2 = 1
\end{equation}

\subsubsection{Quantum Gates}
The circuit applies a sequence of quantum gates:
\begin{align*}
H &= \frac{1}{\sqrt{2}}\begin{pmatrix} 1 & 1 \\ 1 & -1 \end{pmatrix} \text{ (Hadamard)} \\
R_x(\theta) &= \begin{pmatrix} \cos(\theta/2) & -i\sin(\theta/2) \\ -i\sin(\theta/2) & \cos(\theta/2) \end{pmatrix} \text{ (X-rotation)} \\
\text{CNOT} &= |0\rangle\langle0| \otimes I + |1\rangle\langle1| \otimes X \text{ (Entanglement)}
\end{align*}

\subsubsection{Quantum Evolution}
The quantum state evolves through the circuit:
\begin{equation}
|\psi_{\text{out}}\rangle = U_M\cdots U_2U_1|\psi_{\text{in}}\rangle
\end{equation}

where $U_i$ are unitary quantum operations including single-qubit gates and two-qubit entangling gates.

\subsection{Monte Carlo Attention}
The Monte Carlo attention mechanism combines multiple sampling strategies:
\begin{align*}
\text{logits}_{\text{gumbel}} &= \frac{\text{logits} + \mathcal{G}}{0.1} \\
\text{logits}_{\text{temp}} &= \frac{\text{logits}}{0.8} \\
\text{mask}_{\text{top-k}} &= \text{TopK}(\text{logits}, k=40) \\
\text{logits}_{\text{combined}} &= (\text{logits}_{\text{gumbel}} + \text{logits}_{\text{temp}}) \odot \text{mask}_{\text{top-k}} \\
\text{probs} &= \text{softmax}(\text{logits}_{\text{combined}}) \\
\text{probs}_{\text{noisy}} &= \text{softmax}(\log(\text{probs} + \epsilon) + \mathcal{N}_{\text{explore}})
\end{align*}

where $\mathcal{G}$ is Gumbel noise, $\mathcal{N}_{\text{explore}} \sim \mathcal{N}(0, 0.05)$ is exploration noise, and $\epsilon=10^{-10}$.

\subsection{Rotary Embeddings}
Position-dependent rotation matrices applied to queries and keys:
\begin{equation}
\begin{split}
q_{\text{rot}} &= q \odot \text{PE}(L,d) \\
k_{\text{rot}} &= k \odot \text{PE}(L,d)
\end{split}
\end{equation}

where $\text{PE}$ is the positional encoding with base=10000.

\section{Loss Functions}

\subsection{Combined Loss}
The total loss combines cross entropy, KL divergence, and uncertainty:
\begin{equation}
\mathcal{L}_{\text{total}} = \frac{1}{\text{grad\_accum}}\left(\mathcal{L}_{\text{CE}} + 0.1\mathcal{L}_{\text{KL}} + 0.1\mathcal{U} + \mathcal{D}\right)
\end{equation}

where:
\begin{align*}
\mathcal{L}_{\text{CE}} &= -\sum_{i} y_i \log(\hat{y}_i) \\
\mathcal{L}_{\text{KL}} &= \text{KL}(\log(\text{softmax}(\text{logits})) \| \text{probs}) \\
\mathcal{U} &= \text{std}(\{\mathcal{L}_i\}_{i=1}^{N_{\text{MC}}}) \\
\mathcal{D} &= -0.1 \cdot \text{std}(\{\hat{y}_i\}_{i=1}^{N_{\text{MC}}})
\end{align*}

\subsection{Quantum Coherence}
The von Neumann entropy for quantum coherence:
\begin{equation}
S(\rho) = -\sum_i \lambda_i \log(\lambda_i + \epsilon)
\end{equation}

where $\lambda_i$ are eigenvalues of the density matrix $\rho$ and $\epsilon=10^{-10}$.

\section{Optimization}

\subsection{Quantum Adam with High-Dimensional Processing}
The quantum-enhanced Adam optimizer leveraging high-dimensional quantum operations:
\begin{align*}
m_t &= \beta_1 m_{t-1} + (1-\beta_1)g_t \\
v_t &= \beta_2 v_{t-1} + (1-\beta_2)g_t^2 \\
|\psi_t\rangle &= \mathcal{QFT}(e^{i p_t}) \\
\text{Phase}_t &= \text{diag}(\mathcal{U}_t^\dagger \mathcal{U}_t) \\
\text{Energy}_t &= |\langle\psi_t|\mathcal{H}|\psi_t\rangle|^2 \\
q_t &= q_{\text{factor}} \sin(\text{Phase}_t) \sqrt{\text{Energy}_t} \\
m^q_t &= \beta_q m^q_{t-1} + (1-\beta_q)\mathcal{QFT}^{-1}(q_t) \\
p_{t+1} &= p_t - \alpha\frac{m_t}{\sqrt{v_t} + \epsilon} + m^q_t
\end{align*}

where $\mathcal{QFT}$ enables parallel quantum operations, $\mathcal{U}_t$ is the time evolution operator, $\mathcal{H}$ is the system Hamiltonian, and $\beta_q=0.9$ controls quantum momentum. This formulation achieves $O(n\log n)$ complexity through quantum parallelism.

\subsection{Learning Rate Schedule}
Cosine decay with linear warmup:
\begin{equation}
\eta_t = \begin{cases}
\eta_{\text{max}}\frac{t}{t_{\text{warmup}}} & \text{if } t < t_{\text{warmup}} \\
\eta_{\text{min}} + \frac{\eta_{\text{max}}-\eta_{\text{min}}}{2}(1 + \cos(\pi\frac{t-t_{\text{warmup}}}{t_{\text{max}}-t_{\text{warmup}}})) & \text{otherwise}
\end{cases}
\end{equation}

where $\eta_{\text{min}}=3\times10^{-5}$ and $\eta_{\text{max}}=3\times10^{-4}$.

\section{Error Correction and Noise}

\subsection{Surface Code Error Correction}
The Surface code error correction process:
\begin{align*}
|\psi_{\text{encoded}}\rangle &= \mathcal{S}_d|\psi_{\text{in}}\rangle \\
|\psi_{\text{noisy}}\rangle &= \mathcal{N}|\psi_{\text{encoded}}\rangle \\
\text{syndromes} &= \{s_p, s_v\} = \{\langle \psi_{\text{noisy}}|P_i|\psi_{\text{noisy}}\rangle, \langle \psi_{\text{noisy}}|V_j|\psi_{\text{noisy}}\rangle\} \\
\mathcal{C} &= \text{MWPM}(\text{syndromes}) \\
|\psi_{\text{corrected}}\rangle &= \prod_{c \in \mathcal{C}} X_c Z_c |\psi_{\text{noisy}}\rangle \\
|\psi_{\text{out}}\rangle &= \mathcal{S}_d^\dagger|\psi_{\text{corrected}}\rangle
\end{align*}

where $\mathcal{S}_d$ is the Surface code encoding for distance $d$, $P_i$ and $V_j$ are plaquette and vertex stabilizer operators, MWPM is minimum weight perfect matching, and $X_c, Z_c$ are Pauli corrections along correction chains $\mathcal{C}$.

\subsection{Noise Model}
The quantum noise simulation:
\begin{equation}
|\psi_{\text{noisy}}\rangle = \frac{(1 + \mathcal{N}_{\text{amp}})\exp(i\mathcal{N}_{\text{phase}})|\psi\rangle}{\|(1 + \mathcal{N}_{\text{amp}})\exp(i\mathcal{N}_{\text{phase}})|\psi\rangle\|}
\end{equation}

where $\mathcal{N}_{\text{amp}} \sim \mathcal{N}(0,0.01)$ and $\mathcal{N}_{\text{phase}} \sim \mathcal{N}(0,0.005)$.

\section{Monte Carlo Methods}

\subsection{Sampling Strategy}
Multiple sampling approaches combined:
\begin{equation}
\text{logits}_{\text{combined}} = (\text{logits}_{\text{gumbel}} + \text{logits}_{\text{temp}}) \odot \text{mask}_{\text{top-k}}
\end{equation}

where $\text{mask}_{\text{top-k}}$ selects top 40 logits.

\subsection{Uncertainty Estimation}
Mean and uncertainty from MC samples:
\begin{align*}
\bar{y} &= \frac{1}{N_{\text{MC}}}\sum_{i=1}^{N_{\text{MC}}} \hat{y}_i \\
\sigma^2 &= \frac{1}{N_{\text{MC}}}\sum_{i=1}^{N_{\text{MC}}}(\hat{y}_i - \bar{y})^2
\end{align*}

with $N_{\text{MC}}=8$ samples for evaluation.

\bibliographystyle{plainnat}
\bibliography{references}

\end{document}
